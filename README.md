Model Scoring and MLOps Deployment

This project demonstrates the full lifecycle management of a machine learning model, from development and versioning to deployment and monitoring in a production environment. It focuses on MLOps practices, ensuring that models are scalable, maintainable, and continuously monitored.
 
Key Skills Acquired:

    Model Lifecycle Management: Versioning, tracking, and storing models with MLFlow.
    Cloud Deployment: Designing and deploying models in the cloud using automated CI/CD pipelines.
    API Development: Building and deploying prediction APIs with frameworks like FastAPI or Flask.
    Model Monitoring: Tracking model performance, detecting drift, and ensuring long-term maintenance.
    Testing & Automation: Writing unit tests and automating deployment with GitHub Actions.

Technologies Used:

    MLFlow: Model tracking, versioning, and serving via the model registry.
    Git & GitHub: Code versioning and sharing, with continuous integration via GitHub Actions.
    FastAPI/Flask: Building and deploying RESTful APIs for model inference.
    Pytest/Unittest: Automated unit testing for the prediction API.
    GitHub Actions: CI/CD pipeline for automated deployment to the cloud.
    Heroku: Deploy in the cloud
